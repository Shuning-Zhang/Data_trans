{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_access import read_in_data, read_llm_output_data, read_output_data\n",
    "import pandas as pd\n",
    "import os\n",
    "# import xlsxwriter\n",
    "# api key:\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"craigslist_data_wrangler\", \"crime_data_wrangler\", \"potters_wheel_divide\", \"potters_wheel_fold\" ,\n",
    "                     \"potters_wheel_fold_2\", \"potters_wheel_merge_split\", \"potters_wheel_split_fold\", \"potters_wheel_unfold\", \n",
    "                      \"potters_wheel_unfold2\", \"proactive_wrangling_fold\", \"proactive_wrangling_complex\", \"reshape_table_structure_data_wrangler\"]# \n",
    "missing_list = [9, 14, 16, 20, 21, 23, 25, 31, 32, 35, 38, 39, 42,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = './error/'\n",
    "source_path = '../output/'\n",
    "model = 'Llama2-7b-chat-hf/'\n",
    "def calculate_acc():\n",
    "    acc = []\n",
    "    for j in [6,18,24,29,34,41]:\n",
    "        if j in missing_list:\n",
    "            continue\n",
    "        # if j in [30]:\n",
    "        #     acc.append([0,0,j])\n",
    "        #     continue\n",
    "\n",
    "        acc_1_5 = [0,0,j]\n",
    "        for i in range(1,6): \n",
    "            if[j,i] in[[]] or j in [5,8,22,41]:\n",
    "                acc.append([0,0,j])\n",
    "            else:\n",
    "                print(j,i)\n",
    "\n",
    "                path = '../data/foofah/foofah/exp0_'+str(j) + '_'+ str(i)+ '.txt'\n",
    "                input_data, test_data = read_in_data(path)\n",
    "                input_path = source_path+model+'foofah/output_data_0_'+str(j) + '_'+ str(i)+ '.json'\n",
    "                # llama70 = read_llm_output_data(input_path)\n",
    "                #gpt_3_5 = read_llm_output_data('../output/Llama-2-13b-chat-hf/foofah/output_data_0_5_4.json')\n",
    "                gpt_4_0 = read_llm_output_data('../output/chat_gpt_3.5/foofah/new_output_data_0_'+str(j) + '_'+ str(i)+ '.json')\n",
    "                # if os.path.isfile('../output/foofah/foofah/exp0_results_'+str(j) + '_'+ str(i)+ '.txt'):\n",
    "                #     foofah = read_output_data('../output/foofah/foofah/exp0_results_'+str(j) + '_'+ str(i)+ '.txt')\n",
    "                # else:\n",
    "                #     foofah = [[]]\n",
    "                for p, output_data in enumerate([gpt_4_0]):\n",
    "                #compare output_data and test_data\n",
    "                    acc_temp = 0\n",
    "                        # print(j,i)\n",
    "                    for k in range(min(len(output_data),len(test_data[1]))):\n",
    "                        for m in range(min(len(output_data[k]),len(test_data[1][k]))):\n",
    "                            if output_data[k][m] == test_data[1][k][m]:\n",
    "                                acc_temp += 1\n",
    "                    test_case_acc = acc_temp/(len(test_data[1])*len(test_data[1][0]))\n",
    "                    # if test_case_acc < 0.3:\n",
    "                    #     output_path = dest_folder+model+'foofah/'\n",
    "                    #     if not os.path.exists(output_path):\n",
    "                    #         os.makedirs(output_path)\n",
    "                    #     shutil.copy(input_path, output_path)\n",
    "                    acc_1_5[p] += (acc_temp/(len(test_data[1])*len(test_data[1][0])))/5\n",
    "                    acc_1_5[1] = max(acc_1_5[1], acc_temp/(len(test_data[1])*len(test_data[1][0])))\n",
    " \n",
    "\n",
    "        acc.append(acc_1_5)\n",
    "    return(acc)\n",
    "                \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "18 1\n",
      "18 2\n",
      "18 3\n",
      "18 4\n",
      "18 5\n",
      "24 1\n",
      "24 2\n",
      "24 3\n",
      "24 4\n",
      "24 5\n",
      "29 1\n",
      "29 2\n",
      "29 3\n",
      "29 4\n",
      "29 5\n",
      "34 1\n",
      "34 2\n",
      "34 3\n",
      "34 4\n",
      "34 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5733333333333333, 1.0, 6],\n",
       " [0.4543492063492064, 0.7428571428571429, 18],\n",
       " [0.14166666666666666, 0.25, 24],\n",
       " [0.04592592592592592, 0.1111111111111111, 29],\n",
       " [0.5977777777777777, 1.0, 34],\n",
       " [0, 0, 41],\n",
       " [0, 0, 41],\n",
       " [0, 0, 41],\n",
       " [0, 0, 41],\n",
       " [0, 0, 41],\n",
       " [0, 0, 41]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = calculate_acc()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9/1/2008', '9/2/2008', '9/3/2008'],\n",
       " ['', ''],\n",
       " ['Product2', '3', '5', '10'],\n",
       " ['Product3', '0', '1', '4'],\n",
       " ['Product4', '1', '0', '0'],\n",
       " ['Product5', '3', '8', '7'],\n",
       " ['Product6', '9', '2', '1']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_llm_output_data('../output/Llama-2-7b-chat-hf/foofah/output_data_0_6_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(acc)\n",
    "df.to_excel('acc_llama70.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 7b chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[719], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llama2_7b_chat_acc \u001b[38;5;241m=\u001b[39m \u001b[43macc\u001b[49m\n\u001b[1;32m      2\u001b[0m llama2_7b_chat_acc\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "llama2_7b_chat_acc = acc\n",
    "llama2_7b_chat_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2388125724260178"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(llama2_7b_chat_acc)/len(llama2_7b_chat_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat GPT Accuracy 3.5 turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030612244897959183,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.03571428571428571,\n",
       " 0.18681318681318682,\n",
       " 0.13690476190476192,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.06666666666666667,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.058823529411764705,\n",
       " 0.11764705882352941,\n",
       " 0.11764705882352941,\n",
       " 0.11764705882352941]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_gpt_acc = acc\n",
    "chat_gpt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34164760776105313"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(chat_gpt_acc)/len(chat_gpt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# /Users/savannazhang/Desktop/data_trans/output/Llama-2-13b-chat-hf/prose/output_chat_llama2_prose.csv\n",
    "# Load CSV file\n",
    "df = pd.read_csv('../output/mistral/prose/mistral_prose.csv',on_bad_lines='skip')\n",
    "\n",
    "# Sort the DataFrame\n",
    "sorted_df = df.sort_values(by='data', ascending=True)\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV file\n",
    "sorted_df.to_csv('../output/mistral/prose/mistral_prose.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy code and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'potters_wheel_unfold'\n",
    "j = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update i j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"craigslist_data_wrangler\", \"crime_data_wrangler\", \"potters_wheel_divide\", \"potters_wheel_fold\" ,\n",
    "                     \"potters_wheel_fold_2\", \"potters_wheel_merge_split\", \"potters_wheel_split_fold\", \"potters_wheel_unfold\", \n",
    "                     \"potters_wheel_unfold2\", \"proactive_wrangling_fold\", \"proactive_wrangling_complex\", \"reshape_table_structure_data_wrangler\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "j = 0\n",
    "i = name_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape_table_structure_data_wrangler 5\n"
     ]
    }
   ],
   "source": [
    "j += 1\n",
    "if j == 6:\n",
    "    j = 1\n",
    "    idx += 1\n",
    "    i = name_list[idx]\n",
    "print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 1\n"
     ]
    }
   ],
   "source": [
    "j += 1\n",
    "if j == 6:\n",
    "    j = 1\n",
    "    i += 1\n",
    "print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def transform_data(data):\n",
    "    transformed_data = []\n",
    "    for item in data:\n",
    "        phone_number = item.split('-')[2]\n",
    "        integer_part = int(phone_number[:4])\n",
    "        transformed_data.append(integer_part)\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'ZipCode.000002'\n",
    "# 2021!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '../data/foofah/Transformation.Text/'+ x+ '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "r = transform_data(test_data[0])\n",
    "with open('../output/Llama2-70b-chat-hf/prose/output_'+x+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/Llama2-70b-chat-hf/prose/output_'+x+'.json', \"w\") as file: \n",
    "    json.dump([], file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1621,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/Llama-2-13b-chat-hf/prose/output_'+x+'.json', \"w\") as file: \n",
    "    json.dump([[]], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(2) + '_'+ str(3) + '.txt'\n",
    "input_data, test_data = read_in_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "path = \"../output/Llama-2-7b-chat-hf/foofah/output_chat_llama2.csv\"\n",
    "df = pandas.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to LLAma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list =[\"craigslist_data_wrangler\", \"crime_data_wrangler\", \"potters_wheel_divide\", \"potters_wheel_fold\" ,\n",
    "                     \"potters_wheel_fold_2\", \"potters_wheel_merge_split\", \"potters_wheel_split_fold\", \"potters_wheel_unfold\",\n",
    "                     \"potters_wheel_unfold2\", \"proactive_wrangling_fold\", \"proactive_wrangling_complex\", \"reshape_table_structure_data_wrangler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "ii = name_list[idx]\n",
    "jj = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape_table_structure_data_wrangler 5\n"
     ]
    }
   ],
   "source": [
    "jj += 1\n",
    "if jj == 6:\n",
    "    jj = 1\n",
    "    idx += 1\n",
    "    ii = name_list[idx]\n",
    "\n",
    "# jj += 1\n",
    "# if jj == 6:\n",
    "#     ii += 1\n",
    "#     jj = 1\n",
    "print(ii,jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    # Convert data to a dictionary\n",
    "    data_dict = {}\n",
    "    for row in data:\n",
    "        data_dict[row[0]] = row[1:]\n",
    "\n",
    "    # Sort the data by year and month\n",
    "    sorted_data = sorted(data_dict.items(), key=lambda x: (x[0][0], x[0][1]))\n",
    "\n",
    "    # Create a new list with the transformed data\n",
    "    transformed_data = []\n",
    "    for year, month, value in sorted_data:\n",
    "        transformed_data.append([year, month, value])\n",
    "\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1307], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/foofah/foofah/exp0_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ii) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(jj) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m input_data, test_data \u001b[38;5;241m=\u001b[39m read_in_data(path)\n\u001b[0;32m----> 8\u001b[0m r \u001b[38;5;241m=\u001b[39m transform_data(test_data[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# r = transform_data(test_data[0])\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# r = d()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../output/Llama2-70b-chat-hf/foofah/output_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(ii) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(jj)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file: \n",
      "Cell \u001b[0;32mIn[1306], line 12\u001b[0m, in \u001b[0;36mtransform_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a new list with the transformed data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year, month, value \u001b[38;5;129;01min\u001b[39;00m sorted_data:\n\u001b[1;32m     13\u001b[0m     transformed_data\u001b[38;5;241m.\u001b[39mappend([year, month, value])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed_data\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# jj += 1\n",
    "# if jj == 6:\n",
    "#     jj = 1\n",
    "#     ii += 1\n",
    "# print(ii,jj)\n",
    "path = '../data/foofah/foofah/exp0_'+ str(ii) + '_'+ str(jj) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "r = transform_data(test_data[0])\n",
    "# r = transform_data(test_data[0])\n",
    "# r = d()\n",
    "with open('../output/Llama2-70b-chat-hf/foofah/output_'+str(ii) + '_'+ str(jj)+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#r = transform_data(test_data[0])\n",
    "with open('../output/Llama2-70b-chat-hf/foofah/output_'+str(ii) + '_'+ str(jj)+'.json', \"w\") as file: \n",
    "    json.dump([[]], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "j = 1\n",
    "i = name_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape_table_structure_data_wrangler 5\n"
     ]
    }
   ],
   "source": [
    "j += 1\n",
    "if j == 6:\n",
    "    j = 1\n",
    "    idx += 1\n",
    "    i = name_list[idx]\n",
    "print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(input_dataset):\n",
    "    output_dataset = [[''] + [str(i) for i in range(1, 7)]]\n",
    "    current_year = None\n",
    "    current_row = []\n",
    "    for record in input_dataset:\n",
    "        year, month, value = record\n",
    "        if year != current_year:\n",
    "            if current_year is not None:\n",
    "                output_dataset.append(current_row)\n",
    "            current_year = year\n",
    "            current_row = [year]\n",
    "        current_row.append(value)\n",
    "    output_dataset.append(current_row)\n",
    "    return output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n"
     ]
    }
   ],
   "source": [
    "print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(i) + '_'+ str(j) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "# r = transform_data(pd.DataFrame(test_data[0]))\n",
    "r = data_transformation(test_data[0])\n",
    "# r = d()\n",
    "with open('../output/mistral/foofah/output_data_0_'+str(i) + '_'+ str(j)+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/mistral/foofah/output_data_0_'+str(i) + '_'+ str(j)+'.json', \"w\") as file: \n",
    "    json.dump([[]], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/mistral/accuracy_foofah.json', \"w\") as file: \n",
    "    json.dump(acc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_37_5.txt'\n",
    "input_data, test_data = read_in_data(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/prose/exp0_'+ str(i) + '_'+ str(j) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "# r = transform_data(pd.DataFrame(test_data[0]))\n",
    "r = data_transformation(test_data[0])\n",
    "# r = d()\n",
    "with open('../output/mistral/foofah/output_data_0_'+str(i) + '_'+ str(j)+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users/savannazhang/Desktop/data_trans/output/chat_gpt_3.5/prose/output_BillingCode.000002.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_Address.000008.json\n",
      "Address.000008\n",
      "output_Author.000001.json\n",
      "Author.000001\n",
      "output_Number.000028.json\n",
      "Number.000028\n",
      "output_Word.000001.json\n",
      "Word.000001\n",
      "output_Address.000004.json\n",
      "Address.000004\n",
      "output_Honorific.000001.json\n",
      "Honorific.000001\n",
      "output_Meteorite.000001.json\n",
      "Meteorite.000001\n",
      "output_Number.000044.json\n",
      "Number.000044\n",
      ".DS_Store\n",
      "output_Number.000005.json\n",
      "Number.000005\n",
      "output_Name.000030.json\n",
      "Name.000030\n",
      "output_Address.000009.json\n",
      "Address.000009\n",
      "output_Phone.000001.json\n",
      "Phone.000001\n",
      "output_EmergencyCall.000004.json\n",
      "EmergencyCall.000004\n",
      "output_Address.000002.json\n",
      "Address.000002\n",
      "output_Name.000021.json\n",
      "Name.000021\n",
      "output_Gender.000001.json\n",
      "output_Number.000034.json\n",
      "Number.000034\n",
      "output_EmergencyCall.000003.json\n",
      "EmergencyCall.000003\n",
      "output_Phone.000006.json\n",
      "Phone.000006\n",
      "output_ShippingCode.000008.json\n",
      "ShippingCode.000008\n",
      "output_Name.000020.json\n",
      "Name.000020\n",
      "output_BillingCode.000003.json\n",
      "BillingCode.000003\n",
      "output_chat_llama2_70_prose.csv\n",
      "output_Name.000023.json\n",
      "Name.000023\n",
      "output_Airline.000002.json\n",
      "Airline.000002\n",
      "output_Phone.000004.json\n",
      "Phone.000004\n",
      "output_Name.000015.json\n",
      "Name.000015\n",
      "output_Gender.000002.json\n",
      "output_Phone.000005.json\n",
      "Phone.000005\n",
      "output_ShippingCode.000007.json\n",
      "ShippingCode.000007\n",
      "output_Phone.000002.json\n",
      "Phone.000002\n",
      "output_Name.000013.json\n",
      "Name.000013\n",
      "output_Language.000001.json\n",
      "Language.000001\n",
      "output_Name.000025.json\n",
      "Name.000025\n",
      "output_Name.000033.json\n",
      "Name.000033\n",
      "output_Abbreviation.000001.json\n",
      "Abbreviation.000001\n",
      "output_Name.000012.json\n",
      "Name.000012\n",
      "output_Phone.000003.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "acc = []\n",
    "visited_file = []\n",
    "folder_path = \"../data/foofah/Transformation.Text/\"\n",
    "answer_path = \"../output/Llama2-70b-chat-hf/prose/\"\n",
    "for sub_file in os.listdir(answer_path):\n",
    "    print(sub_file)\n",
    "    if sub_file not in [ '.DS_Store','output_chat_llama2_70_prose.csv','output_Phone.000003.json','output_Gender.000001.json','output_Gender.000002.json']:\n",
    "       \n",
    "        temp_sub_file = sub_file.split(\"_\")\n",
    "        temp_sub_file = temp_sub_file[1]\n",
    "        print(temp_sub_file[:-5])\n",
    "\n",
    "        visited_file.append(sub_file)\n",
    "        file_path = \"../data/foofah/Transformation.Text/\"+temp_sub_file[:-5]+ '.txt'\n",
    "        input_data, test_data =read_in_data(file_path)\n",
    "        answer_path = \"../output/Llama2-70b-chat-hf/prose/\"+sub_file\n",
    "\n",
    "        with open(answer_path, 'rb') as f:\n",
    "            output_data = json.load(f)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        if output_data:\n",
    "            acc_temp = 0\n",
    "                    # print(j,i)\n",
    "            for k in range(min(len(output_data),len(test_data[1]))):\n",
    "                for j in range(min(len(output_data[k]),len(test_data[1][k]))):\n",
    "                    if output_data[k][j] == test_data[1][k][j]:\n",
    "                        acc_temp += 1\n",
    "            acc.append([temp_sub_file, acc_temp/max(len(output_data),len(test_data[1]))])\n",
    "        else:\n",
    "            acc.append([temp_sub_file,0])\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(acc)\n",
    "df.to_excel('acc_llama2-70_p.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+str(4) + '_'+ str(3)+ '.txt'\n",
    "input_data, test_data = read_in_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(path, 'rb') as f:\n",
    "    output_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_table(input_table):\n",
    "    output_table = []\n",
    "    \n",
    "    for row in input_table:\n",
    "        car, color, price = row\n",
    "        output_table.append([car, color])\n",
    "        output_table.append([car, price])\n",
    "    \n",
    "    return output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Toyota', 'White', '2000'],\n",
       "  ['Nissan', 'Red', '4000'],\n",
       "  ['Honda', 'Black', '1000']],\n",
       " [['Toyota', 'White'],\n",
       "  ['Toyota', '2000'],\n",
       "  ['Nissan', 'Red'],\n",
       "  ['Nissan', '4000'],\n",
       "  ['Honda', 'Black'],\n",
       "  ['Honda', '1000']]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Toyota', 'White'],\n",
       " ['Toyota', '2000'],\n",
       " ['Nissan', 'Red'],\n",
       " ['Nissan', '4000'],\n",
       " ['Honda', 'Black'],\n",
       " ['Honda', '1000']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_table(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 36',\n",
       "   '4718',\n",
       "   'RM 0908081',\n",
       "   '26',\n",
       "   'RM 20',\n",
       "   '2538.25',\n",
       "   'RM 0815283',\n",
       "   '26',\n",
       "   'RM 16',\n",
       "   '75',\n",
       "   'RM 0915258',\n",
       "   '26',\n",
       "   'RM 12',\n",
       "   '37.5',\n",
       "   'RM 0909113',\n",
       "   '26',\n",
       "   'RM 15',\n",
       "   '2.25',\n",
       "   'RM 0804010',\n",
       "   '26',\n",
       "   'RM 27',\n",
       "   '90',\n",
       "   'RM 0913217',\n",
       "   '26',\n",
       "   'RM 32',\n",
       "   '37.5',\n",
       "   'RM 0911174',\n",
       "   '26',\n",
       "   'RM 43',\n",
       "   '1.5',\n",
       "   'Err:512',\n",
       "   'Err:512',\n",
       "   'Err:512',\n",
       "   'Err:512',\n",
       "   'Err:512',\n",
       "   'Err:512']],\n",
       " [['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 36',\n",
       "   '4718',\n",
       "   'RM 0908081',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 20',\n",
       "   '2538.25',\n",
       "   'RM 0815283',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 16',\n",
       "   '75',\n",
       "   'RM 0915258',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 12',\n",
       "   '37.5',\n",
       "   'RM 0909113',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 15',\n",
       "   '2.25',\n",
       "   'RM 0804010',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 27',\n",
       "   '90',\n",
       "   'RM 0913217',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 32',\n",
       "   '37.5',\n",
       "   'RM 0911174',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'RM 43',\n",
       "   '1.5',\n",
       "   'RM 0908084',\n",
       "   '26'],\n",
       "  ['011/2010-11',\n",
       "   '5/3/2010',\n",
       "   'TT-501',\n",
       "   'FG-011',\n",
       "   'DD 1004053',\n",
       "   '0.851',\n",
       "   'Err:512',\n",
       "   'Err:512',\n",
       "   'Err:512',\n",
       "   'Err:512']]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_data(input_list):\n",
    "    # Step 1: Extract the first two elements of each list (ID and Type)\n",
    "    id_type_list = [item[:2] for item in input_list]\n",
    "    \n",
    "    # Step 2: Convert the third element (Description) to lowercase\n",
    "    desc_list = [item[2].lower() for item in input_list]\n",
    "    \n",
    "    # Step 3: Remove empty strings from the list\n",
    "    cleaned_list = [item for item in desc_list if item!= '']\n",
    "    \n",
    "    # Step 4: Join the ID, Type, and Description into a single string\n",
    "    transformed_list = [f\"{id_type_list[0]}{id_type_list[1]}{cleaned_list[0]}\" for item in input_list]\n",
    "    \n",
    "    return transformed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
